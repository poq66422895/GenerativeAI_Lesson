{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.事前準備"
      ],
      "metadata": {
        "id": "35FALtqOToxs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在我們開始寫神經網路之前，還沒安裝的話要先安裝gradio這個套件以進行最後的簡易測試網頁"
      ],
      "metadata": {
        "id": "KjfUrpjkULrH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF47oEjT5Pwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "71e0caa7-64b7-412e-9aa7-348ee8b640c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "安裝完gradio後，我們需要import一些必須的套件，包括數據顯示和分析以及tensorflow提供的神經網路等等的套件"
      ],
      "metadata": {
        "id": "ZIHy3JQ1UZAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# 常用的數據分析和畫圖套件\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# tensorflow其中的一些神經網路套件\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# 互動設計用的套件\n",
        "from ipywidgets import interact_manual\n",
        "\n",
        "# 剛剛安裝的Gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Qc0nX4e5STcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.讀入資料集"
      ],
      "metadata": {
        "id": "7woprYCkZVgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "老師這一次使用的是MNIST這個dataset，我們可以從keras中輕鬆的讀進來"
      ],
      "metadata": {
        "id": "ghWRgEnFZZu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "z9SeKByqZnfG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "雖然說MNIST這個dataset很有名且不複雜，其實並不用去分析裡面的data，但一般建立模型的時候先去了解資料的樣子是很重要的，因此這邊我還是先來稍微看一下裡面的資料的樣子"
      ],
      "metadata": {
        "id": "HavUhyM1bdCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'資料集的Shape: {x_train.shape}')\n",
        "print(f'資料的樣子: {x_train}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XxgQOG1bzXA",
        "outputId": "0fb707f2-e598-4acc-a696-131d31b67658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "資料集的Shape: (60000, 28, 28)\n",
            "資料的樣子: [[[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]\n",
            "\n",
            " [[0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]\n",
            "  [0 0 0 ... 0 0 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到MNIST的data是一個28x28的矩陣，共有六萬筆資料"
      ],
      "metadata": {
        "id": "8fbZfiBDyLVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.事前處理"
      ],
      "metadata": {
        "id": "uHLPPKnhyuGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "由於資料本身是28x28的二維矩陣，而我們要建立的標準神經網路只能應付一維的資料，因此我們需要先將所有資料reshape成28x28=784的樣子。而資料本身的數值是一個greyscale的pixel values，range是從0到255，因此我們把它除以255就可以將數值變為0到1之間的數值，我問GPT後得知了這樣做可以幫助模型訓練得更快和可以幫助模型的收斂。"
      ],
      "metadata": {
        "id": "xPGQGaePyyWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000, 784)/255\n",
        "x_test = x_test.reshape(10000, 784)/255"
      ],
      "metadata": {
        "id": "34HVTZVPzNCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接著因為我們要處理的手寫辨識是一個分類問題，因此我們需要進行one-hot-encoding"
      ],
      "metadata": {
        "id": "keTEnFEO10Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "eDmPW72n2YOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.開始建構神經網路"
      ],
      "metadata": {
        "id": "FcDuzvmK25Oe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我們對資料做好事前的處理後，就可以開始建構我們的神經網路了。首先先打開一個標準空白的神經網路，接著利用add( )一步一步的建立我們神經網路的每一層。由於第一層的時候，TensorFlow不知道我們的參數長怎樣，因此需要我們告訴它，但之後的每一層的input就是前一層的output，因此不需要我們去告訴它了。"
      ],
      "metadata": {
        "id": "uEZsAQEP3Ty_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N1 = 20\n",
        "N2 = 20\n",
        "N3 = 20\n",
        "N4 = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dense(N4, activation='relu'))"
      ],
      "metadata": {
        "id": "_XhS3tE22946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d7eeeeea-2e1f-47e5-9994-aa79827c0e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "接著我們還差一個output層，我們的結果是0-9共十個，因此這個output層的神經元數便是10，同時使用softmax當激發函數以使所有結果的幾率加起來是1。"
      ],
      "metadata": {
        "id": "Kmp6T1ZJ4MXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "puSpZuMF4rZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下來就可以去實際建構我們的神經網路了，我們使用mse當做loss function，SGD為optimizer"
      ],
      "metadata": {
        "id": "eYFQ2Bby4w-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JfNX2oql4_q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.測試結果"
      ],
      "metadata": {
        "id": "8u3qYCBt5Sy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "結構好我們的網路後，可以開始訓練並看看我們的模型表現如何了"
      ],
      "metadata": {
        "id": "ILuSaTIt5V4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=100, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTZEGRiT5c0Y",
        "outputId": "8dc857c7-1620-4f8c-883d-f84da0329d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.0633 - loss: 0.0899\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1461 - loss: 0.0893\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2164 - loss: 0.0881\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2746 - loss: 0.0831\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4695 - loss: 0.0711\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5661 - loss: 0.0584\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6775 - loss: 0.0462\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7832 - loss: 0.0342\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8249 - loss: 0.0267\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.0235\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7acb68b58bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U8AycIT52pi",
        "outputId": "a610a852-cf7a-49b6-fa59-872b7c2b468d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8426 - loss: 0.0235\n",
            "loss: 0.02059396170079708\n",
            "正確率 0.8633000254631042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.測試不同參數及function的結果如何"
      ],
      "metadata": {
        "id": "up3Gm2bk6kK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N1 = 20\n",
        "N2 = 20\n",
        "N3 = 20\n",
        "N4 = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dense(N4, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=100, epochs=10)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4SoQuJ_6qes",
        "outputId": "74fa8dd5-07c8-4261-cb91-67a0b2169413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5015 - loss: 1.4121\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.3302\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2467\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.2006\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1799\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9516 - loss: 0.1654\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9561 - loss: 0.1503\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1390\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1344\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.1267\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1564\n",
            "loss: 0.13871487975120544\n",
            "正確率 0.9603000283241272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到換成categorical crossentropy這個loss function後，我們模型的表現變好了很多，因為CCE就是非常適合分類問題的，它可以最大化分類到正確答案的幾率"
      ],
      "metadata": {
        "id": "FZm38L977kLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "N1 = 20\n",
        "N2 = 20\n",
        "N3 = 20\n",
        "N4 = 20\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dense(N4, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=100, epochs=10)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR4G_IDQ7jwJ",
        "outputId": "85e0a6d6-9f57-458a-b4a4-7d64b6030b2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6392 - loss: 1.1070\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2695\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9401 - loss: 0.2050\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.1714\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1535\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9563 - loss: 0.1450\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9608 - loss: 0.1306\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1237\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1207\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1053\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9536 - loss: 0.1537\n",
            "loss: 0.14126631617546082\n",
            "正確率 0.9570000171661377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以看到將optimizer換成Adam後模型的表現沒有明顯變化。看來原本的learning rate就足夠了。"
      ],
      "metadata": {
        "id": "xqt7RFq_8BdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N1 = 384\n",
        "N2 = 384\n",
        "N3 = 384\n",
        "N4 = 384\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dense(N4, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=100, epochs=10)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhJDWixp7xRX",
        "outputId": "cbc816e8-a7d2-491e-d5c5-baeb19cb252c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7701 - loss: 0.7672\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1593\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1025\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0701\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0543\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0419\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0336\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0241\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0180\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0132\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0779\n",
            "loss: 0.06765162199735641\n",
            "正確率 0.9803000092506409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下是一些調整神經元數量的嘗試得出的結果:\n",
        "*   (64,64,64,64): 0.967\n",
        "*   (128,64,32,16): 0.973\n",
        "*   (256,128,64,32): 0.978\n",
        "*   (128,128,128,128): 0.978\n",
        "*   (256,256,256,256): 0.980\n",
        "*   (384,384,384,384): 0.980\n",
        "\n",
        "根據以上的測試，看起來256,256,256,256的神經元就足夠抓取圖像中的特徵了，更多的神經元有可能會造成overfitting的問題。\n"
      ],
      "metadata": {
        "id": "oyb-ELFH8xhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N1 = 256\n",
        "N2 = 256\n",
        "N3 = 256\n",
        "N4 = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dense(N4, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=20, epochs=10)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-pNZXoN-ZQQ",
        "outputId": "4726b387-a021-406b-a4d4-1fc074728947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8542 - loss: 0.4559\n",
            "Epoch 2/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.1021\n",
            "Epoch 3/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9787 - loss: 0.0681\n",
            "Epoch 4/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0497\n",
            "Epoch 5/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0382\n",
            "Epoch 6/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9901 - loss: 0.0306\n",
            "Epoch 7/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0201\n",
            "Epoch 8/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0167\n",
            "Epoch 9/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9955 - loss: 0.0143\n",
            "Epoch 10/10\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0138\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9795 - loss: 0.0830\n",
            "loss: 0.0747981145977974\n",
            "正確率 0.9811999797821045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下是測試batch size跟epochs的影響:\n",
        "*   (64,15): 0.977\n",
        "*   (64,10): 0.979\n",
        "*   (32,10): 0.982\n",
        "*   (32,15): 0.983\n",
        "*   (100,15): 0.977\n",
        "*   (20,10): 0.981\n",
        "\n",
        "可以看到batch size跟epochs的改變，讓模型的表現再進步了一點點，畢竟0.98已經很高了，有一點點的進步已經是很難的事情了\n",
        "\n"
      ],
      "metadata": {
        "id": "MN6p5nCc-58V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "N1 = 256\n",
        "N2 = 256\n",
        "N3 = 256\n",
        "N4 = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(N4, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=15)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooJqItza_94f",
        "outputId": "f5295aaa-ea29-4630-fc5e-8acc02b75c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.6231\n",
            "Epoch 2/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1675\n",
            "Epoch 3/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9655 - loss: 0.1166\n",
            "Epoch 4/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.0937\n",
            "Epoch 5/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0814\n",
            "Epoch 6/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9774 - loss: 0.0738\n",
            "Epoch 7/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0691\n",
            "Epoch 8/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0558\n",
            "Epoch 9/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0557\n",
            "Epoch 10/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0498\n",
            "Epoch 11/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9866 - loss: 0.0435\n",
            "Epoch 12/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0404\n",
            "Epoch 13/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0375\n",
            "Epoch 14/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9881 - loss: 0.0363\n",
            "Epoch 15/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0337\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9760 - loss: 0.0866\n",
            "loss: 0.06718938052654266\n",
            "正確率 0.9814000129699707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "由於更多的神經元有可能導致overfitting的問題，因此我這邊加上Dropout去測試看看有沒有進步，可以看到結果並沒有明顯變化，甚至有一點退步。"
      ],
      "metadata": {
        "id": "7GvioqeTAXOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Gradio測試"
      ],
      "metadata": {
        "id": "xmJu5ftvB8fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N1 = 256\n",
        "N2 = 256\n",
        "N3 = 256\n",
        "N4 = 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N1, input_dim=784, activation='relu'))\n",
        "model.add(Dense(N2, activation='relu'))\n",
        "model.add(Dense(N3, activation='relu'))\n",
        "model.add(Dense(N4, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=15)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('loss:', score[0])\n",
        "print('正確率', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGLp1BWfCBJC",
        "outputId": "7d9b5c36-9d48-41b6-cda5-c97287bce7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8313 - loss: 0.5313\n",
            "Epoch 2/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9663 - loss: 0.1112\n",
            "Epoch 3/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0696\n",
            "Epoch 4/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0528\n",
            "Epoch 5/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9895 - loss: 0.0349\n",
            "Epoch 6/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0300\n",
            "Epoch 7/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0242\n",
            "Epoch 8/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0173\n",
            "Epoch 9/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0137\n",
            "Epoch 10/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9963 - loss: 0.0120\n",
            "Epoch 11/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0120\n",
            "Epoch 12/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0061\n",
            "Epoch 13/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0057\n",
            "Epoch 14/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0095\n",
            "Epoch 15/15\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0049\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0900\n",
            "loss: 0.07394374161958694\n",
            "正確率 0.9843999743461609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_image(pic):\n",
        "    image = np.array(pic[\"layers\"][0], dtype=np.float32)\n",
        "    image = image.astype(np.uint8)\n",
        "    image_pil = Image.fromarray(image)\n",
        "    background = Image.new(\"RGB\", image_pil.size, (255, 255, 255))\n",
        "    background.paste(image_pil, mask=image_pil.split()[3])\n",
        "    image_pil = background\n",
        "    image_gray = image_pil.convert(\"L\")\n",
        "    img_array = np.array(image_gray.resize((28, 28), resample=Image.LANCZOS))\n",
        "    img_array = 255 - img_array\n",
        "    img_array = img_array.reshape(1, 784) / 255.0\n",
        "    return img_array\n",
        "\n",
        "def recognize_digit(pic):\n",
        "    img_array = resize_image(pic)\n",
        "    prediction = model.predict(img_array).flatten()\n",
        "    labels = list('0123456789')\n",
        "    return {labels[i]: float(prediction[i]) for i in range(10)}\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=recognize_digit,\n",
        "    inputs=gr.Sketchpad(),\n",
        "    outputs=gr.Label(num_top_classes=3),\n",
        "    title=\"MNIST 手寫辨識\",\n",
        "    description=\"請在畫板上繪製數字\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "collapsed": true,
        "id": "gMCS-Rz-Kait",
        "outputId": "3aa0388c-2e82-4a42-a7e1-26899bf5fa0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6a9a496e8d48d8a9ba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6a9a496e8d48d8a9ba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://6a9a496e8d48d8a9ba.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}